{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c1f2610",
   "metadata": {},
   "source": [
    "## Another approach using holograph (not working)\n",
    "#### This approach is inspired by https://arxiv.org/ftp/arxiv/papers/2105/2105.07608.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0aa57fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, value, depth, available):\n",
    "        self.value = value\n",
    "        self.depth = depth\n",
    "        self.available = available\n",
    "    def merge_available(self, other):\n",
    "        \n",
    "        for i in other:\n",
    "            if i not in self.available:\n",
    "                self.available.append(i)\n",
    "        '''\n",
    "        for i in self.available:\n",
    "            if i not in other:\n",
    "                self.available.remove(i)\n",
    "        '''\n",
    "    \n",
    "    def __str__(self):\n",
    "        ret=\"value is:\"+repr(self.value)+\"    depth is:\"+repr(self.depth)\n",
    "        return ret\n",
    "        \n",
    "def readFile(filename):\n",
    "    file_tmp = open(filename, 'r')\n",
    "    lines = file_tmp.readlines()\n",
    "    v = int(lines[3].split(' ')[2])\n",
    "    lines = lines[6:]\n",
    "    lines.pop()\n",
    "    lines.pop()\n",
    "    return v,lines\n",
    "\n",
    "def buildAjacencyList(lines, v_num):\n",
    "    v_dictionary = {}\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        splitted = line.split(' ')\n",
    "        #print(splitted)\n",
    "        if splitted[0] in v_dictionary.keys():\n",
    "            v_dictionary[splitted[0]].append(splitted[1])\n",
    "        else:\n",
    "            v_dictionary[splitted[0]] = []\n",
    "            (v_dictionary[splitted[0]]).append(splitted[1])\n",
    "            \n",
    "        if splitted[1] in v_dictionary.keys():    \n",
    "            v_dictionary[splitted[1]].append(splitted[0])\n",
    "        else:\n",
    "            v_dictionary[splitted[1]] = []\n",
    "            (v_dictionary[splitted[1]]).append(splitted[0])\n",
    "    return v_dictionary\n",
    "\n",
    "def print_matrix_list(list):\n",
    "    for i in list:\n",
    "        print(\"------------------------------\")\n",
    "        if i != None:\n",
    "            print(i)\n",
    "def algorithm(v_dictionary, starting_vertex, v_num):\n",
    "    # create node for starting vertex\n",
    "    #get all keys\n",
    "    all_values = []\n",
    "    for i in v_dictionary.keys():\n",
    "        all_values.append(i)\n",
    "        \n",
    "    temp_avai = copy.copy(all_values)\n",
    "    temp_avai.remove(starting_vertex)\n",
    "    starting_v = Node(starting_vertex,0,temp_avai)\n",
    "    #print(starting_v.available)\n",
    "    # create (v_num-1)*(v_num) matrix to store nodes\n",
    "    \n",
    "    matrix = [ [None for _ in range(v_num) ] for _ in range(v_num-1)]      # excluding starting vertex\n",
    "    #matrix[1][1] = 10\n",
    "    #print(matrix)\n",
    "    # doing the starting vertex\n",
    "    #print(v_dictionary[starting_vertex])\n",
    "    for n in v_dictionary[starting_vertex]:\n",
    "        #print(n)\n",
    "        temp_avai = copy.copy(starting_v.available)\n",
    "        temp_avai.remove(n)\n",
    "        matrix[0][int(n)-1] = Node(n,1,temp_avai)\n",
    "        #print(matrix[0][int(n)-1].available)\n",
    "    #print(matrix)\n",
    "    \n",
    "    # do the remaining levels\n",
    "    for i in range(0,v_num-2):\n",
    "        for j in range(0,v_num):\n",
    "            if matrix[i][j] != None:\n",
    "                #print(i)\n",
    "                #print(j)\n",
    "                node = matrix[i][j]\n",
    "                #print(node)\n",
    "                for n in v_dictionary[node.value]:\n",
    "                    if n in node.available:\n",
    "                        temp_avai = copy.copy(node.available)\n",
    "                        temp_avai.remove(n)\n",
    "                        \n",
    "                        #print(matrix[i+1][int(n)-1])\n",
    "                        if matrix[i+1][int(n)-1] == None:\n",
    "                            #print(\"node create\")\n",
    "                            #print(int(n)-1)\n",
    "                            matrix[i+1][int(n)-1] = Node(n,i+2,temp_avai)\n",
    "\n",
    "                        else:\n",
    "                            #print(\"node merge\")\n",
    "                            #print(i)\n",
    "                            #print(matrix[i][int(n)-1])\n",
    "                            #print(matrix[i+1][int(n)-1])\n",
    "                            matrix[i+1][int(n)-1].merge_available(temp_avai)\n",
    "        #print_matrix_list(matrix[i+1])\n",
    "    return matrix\n",
    "\n",
    "\n",
    "\n",
    "path = './FHCPCS'\n",
    "v_num, lines = readFile(path+'/graph1.hcp')    \n",
    "v_dictionary = buildAjacencyList(lines, v_num)\n",
    "\n",
    "result = algorithm(v_dictionary, '1', v_num)\n",
    "\n",
    "#print(v_dictionary.keys())\n",
    "#print(v_num)\n",
    "#print(result)\n",
    "#print_matrix_list(result[64])\n",
    "#print(result[64][1].available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af079460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': ['3', '9', '61'], '3': ['1', '40', '46'], '9': ['1', '25', '35'], '61': ['1', '14', '49'], '2': ['17', '31', '51'], '17': ['2', '21', '37'], '31': ['2', '7', '29'], '51': ['2', '13', '48'], '40': ['3', '6', '59'], '46': ['3', '25', '62'], '4': ['42', '47', '63'], '42': ['4', '41', '55'], '47': ['4', '12', '50'], '63': ['4', '8', '15'], '5': ['8', '18', '39'], '8': ['5', '50', '63'], '18': ['5', '15', '23'], '39': ['5', '34', '49'], '6': ['30', '40', '62'], '30': ['6', '54', '56'], '62': ['6', '24', '46'], '7': ['13', '31', '58'], '13': ['7', '51', '66'], '58': ['7', '41', '64'], '50': ['8', '34', '47'], '25': ['9', '36', '46'], '35': ['9', '14', '32'], '10': ['16', '27', '44'], '16': ['10', '52', '53'], '27': ['10', '60', '65'], '44': ['10', '22', '28'], '11': ['19', '45', '54'], '19': ['11', '52', '56'], '45': ['11', '28', '38'], '54': ['11', '30', '59'], '12': ['21', '47', '55'], '21': ['12', '17', '34'], '55': ['12', '37', '42'], '66': ['13', '33', '64'], '14': ['35', '57', '61'], '57': ['14', '20', '23'], '15': ['18', '20', '63'], '20': ['15', '32', '57'], '52': ['16', '19', '28'], '53': ['16', '48', '65'], '37': ['17', '29', '55'], '23': ['18', '49', '57'], '56': ['19', '24', '30'], '32': ['20', '35', '36'], '34': ['21', '39', '50'], '22': ['38', '44', '60'], '38': ['22', '45', '59'], '60': ['22', '26', '27'], '49': ['23', '39', '61'], '24': ['36', '56', '62'], '36': ['24', '25', '32'], '26': ['43', '60', '64'], '43': ['26', '33', '65'], '64': ['26', '58', '66'], '65': ['27', '43', '53'], '28': ['44', '45', '52'], '29': ['31', '37', '41'], '41': ['29', '42', '58'], '33': ['43', '48', '66'], '48': ['33', '51', '53'], '59': ['38', '40', '54']}\n"
     ]
    }
   ],
   "source": [
    "print(v_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4418d5c",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "#### This approach does not work. By unioning the available options, we lose information about specific paths. One counterexample is that:\n",
    "1 2\n",
    "\n",
    "1 4\n",
    "\n",
    "2 3\n",
    "\n",
    "4 3\n",
    "\n",
    "2 5\n",
    "\n",
    "4 5\n",
    "\n",
    "\n",
    "#### In this case, the 5 in the last level still have 2 and 4 as available options, but in fact, both 2 and 4 should be unavailable.\n",
    "#### The paper uses a very complexly written algorithm, but as far as I understand, it is essentially doing parent expansion on new nodes (or backtracking through all posibilities in another sense), which is still exponential time in the worst case. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
